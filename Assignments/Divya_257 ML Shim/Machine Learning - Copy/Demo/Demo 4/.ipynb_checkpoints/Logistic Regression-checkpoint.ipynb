{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "GNZAnr5s9G31"
   },
   "outputs": [],
   "source": [
    "# Import the dependencies\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "a1sjuqNA9G34",
    "outputId": "88e2422b-81ff-4d3a-fd60-f07d791b2dbf"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data set\n",
    "data = sns.load_dataset(\"iris\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "sSWD_Txc9G35"
   },
   "outputs": [],
   "source": [
    "#Prepare the training set\n",
    "\n",
    "# X = feature values, all the columns except the last column\n",
    "X = data.iloc[:, :-1]\n",
    "\n",
    "# y = target values, last column of the data frame\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0tDudxdF9G36"
   },
   "outputs": [],
   "source": [
    "#Split the data into 80% training and 20% testing\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBFk365g9G37",
    "outputId": "216a111f-5528-48f2-c034-9bec2f515479"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=1000,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train the model\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(x_train, y_train) #Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GwifJrvl9G37",
    "outputId": "910bddb1-9215-4767-9055-1069603d4dfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['versicolor' 'versicolor' 'virginica' 'setosa' 'versicolor' 'setosa'\n",
      " 'versicolor' 'versicolor' 'setosa' 'virginica' 'setosa' 'versicolor'\n",
      " 'versicolor' 'versicolor' 'versicolor' 'setosa' 'setosa' 'versicolor'\n",
      " 'versicolor' 'virginica' 'virginica' 'virginica' 'setosa' 'virginica'\n",
      " 'virginica' 'setosa' 'setosa' 'virginica' 'setosa' 'versicolor']\n"
     ]
    }
   ],
   "source": [
    "#Test the model\n",
    "predictions = model.predict(x_test)\n",
    "print(predictions)# printing predictions\n",
    "#print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UGbe2fLb9G38",
    "outputId": "86fd9536-6889-4235-8518-e0111041f2fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "print( accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qm6W9q3Z9G39",
    "outputId": "44396c80-4ad1-4fc3-e612-5badf407bc30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1  8]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pDm9cAe9QTmu"
   },
   "source": [
    "Actual count: setosa - 8 versicolor - 12 virginica - 10\n",
    "\n",
    "Predicted count: setosa - 8 versicolor - 12 virginica - 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "0DH93XIZ9G3_",
    "outputId": "22a9001c-5bab-4173-d74a-6aab8dfcf217"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot confusion matrix\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "# confusion matrix sns heatmap \n",
    "ax = plt.axes()\n",
    "df_cm = cm\n",
    "sns.heatmap(df_cm, annot=True, annot_kws={\"size\": 10}, fmt='d',cmap=\"Blues\", ax = ax )\n",
    "ax.set_title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OR8JDAY-O-mY"
   },
   "source": [
    "# K-Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "poTFgndcoH0t",
    "outputId": "75b44127-8ee7-4294-ce53-76bba3e38b05"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the data set\n",
    "data = sns.load_dataset(\"iris\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "H0ckn4mgoevz"
   },
   "outputs": [],
   "source": [
    "#Prepare the training set\n",
    "\n",
    "# X = feature values, all the columns except the last column\n",
    "X = data.iloc[:, :-1]\n",
    "\n",
    "# y = target values, last column of the data frame\n",
    "y = data.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Cp41mzGnogp7"
   },
   "outputs": [],
   "source": [
    "# Declaring a model\n",
    "model = LogisticRegression(max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FIPYvviKorLQ",
    "outputId": "df4b3c68-c115-4cb6-d8d0-20cba10443d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Index:  [  0   1   2   3   4   5   6   7   8  10  11  13  14  15  16  17  20  21\n",
      "  22  23  24  25  26  27  28  29  30  32  33  34  35  37  38  39  40  41\n",
      "  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  62  63  65  66  67  69  70  71  72  74  75  77  79  80  81  83\n",
      "  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 111 112 113 114 115 116 117 119 120 121\n",
      " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 142 143 144 145 146 147 148 149]\n",
      "Test Index:  [  9  12  18  19  31  36  64  68  73  76  78  82 110 118 141] \n",
      "\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  27  28  31  32  33  34  35  36  37  38\n",
      "  39  40  41  42  43  44  46  47  48  49  50  51  52  53  54  57  58  59\n",
      "  60  61  62  63  64  65  66  67  68  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96\n",
      "  97  98  99 100 101 102 103 105 106 107 109 110 111 112 113 114 115 116\n",
      " 117 118 119 120 121 122 123 124 125 126 129 130 133 134 135 136 137 138\n",
      " 139 140 141 142 144 146 147 148 149]\n",
      "Test Index:  [ 26  29  30  45  55  56  69 104 108 127 128 131 132 143 145] \n",
      "\n",
      "Train Index:  [  0   1   2   3   5   6   7   8   9  12  13  14  17  18  19  20  21  23\n",
      "  24  25  26  28  29  30  31  33  34  35  36  37  38  39  40  41  43  44\n",
      "  45  46  47  48  49  50  52  53  54  55  56  57  58  59  60  61  62  63\n",
      "  64  66  67  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82\n",
      "  83  84  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102\n",
      " 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120\n",
      " 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 139 140 141 143 144 145 147 148 149]\n",
      "Test Index:  [  4  10  11  15  16  22  27  32  42  51  65  85  86 142 146] \n",
      "\n",
      "Train Index:  [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  29  30  31  32  33  34  35  36  37\n",
      "  38  39  41  42  43  45  46  47  48  49  50  51  52  53  54  55  56  57\n",
      "  58  59  61  62  63  64  65  68  69  70  71  72  73  74  76  77  78  79\n",
      "  80  82  83  84  85  86  87  88  89  90  91  92  93  94  95  97  98  99\n",
      " 100 101 102 103 104 106 107 108 110 111 112 113 114 115 116 117 118 119\n",
      " 120 121 123 124 125 126 127 128 129 130 131 132 134 135 136 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "Test Index:  [  0  28  40  44  60  66  67  75  81  96 105 109 122 133 137] \n",
      "\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  26  27  28  29  30  31  32  34  35  36  37  38  40\n",
      "  41  42  43  44  45  46  48  49  50  51  52  53  54  55  56  57  58  59\n",
      "  60  61  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  96  98  99\n",
      " 100 102 103 104 105 106 107 108 109 110 111 112 114 115 116 118 119 120\n",
      " 121 122 124 125 126 127 128 129 130 131 132 133 134 135 136 137 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "Test Index:  [ 23  24  25  33  39  47  62  94  95  97 101 113 117 123 138] \n",
      "\n",
      "Train Index:  [  0   1   2   3   4   6   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  36  37  38  39\n",
      "  40  41  42  44  45  46  47  48  50  51  52  54  55  56  57  58  59  60\n",
      "  61  62  63  64  65  66  67  68  69  71  72  73  74  75  76  78  79  81\n",
      "  82  83  85  86  87  88  89  90  91  92  94  95  96  97  98  99 100 101\n",
      " 102 103 104 105 106 107 108 109 110 112 113 115 116 117 118 119 120 121\n",
      " 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 146 147 149]\n",
      "Test Index:  [  5   7  34  35  43  49  53  70  77  80  84  93 111 114 148] \n",
      "\n",
      "Train Index:  [  0   1   2   4   5   6   7   9  10  11  12  14  15  16  18  19  20  21\n",
      "  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  39  40\n",
      "  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58\n",
      "  59  60  61  62  63  64  65  66  67  68  69  70  71  73  74  75  76  77\n",
      "  78  79  80  81  82  84  85  86  87  88  90  91  92  93  94  95  96  97\n",
      "  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116\n",
      " 117 118 121 122 123 124 126 127 128 129 130 131 132 133 137 138 139 140\n",
      " 141 142 143 144 145 146 147 148 149]\n",
      "Test Index:  [  3   8  13  17  38  72  83  89  98 119 120 125 134 135 136] \n",
      "\n",
      "Train Index:  [  0   1   3   4   5   7   8   9  10  11  12  13  14  15  16  17  18  19\n",
      "  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  47  48  49  51  52  53  55  56  57  58\n",
      "  60  62  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78  80\n",
      "  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98\n",
      "  99 101 102 103 104 105 106 107 108 109 110 111 113 114 116 117 118 119\n",
      " 120 121 122 123 124 125 127 128 129 130 131 132 133 134 135 136 137 138\n",
      " 140 141 142 143 144 145 146 148 149]\n",
      "Test Index:  [  2   6  46  50  54  59  61  63  79 100 112 115 126 139 147] \n",
      "\n",
      "Train Index:  [  0   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  38\n",
      "  39  40  42  43  44  45  46  47  49  50  51  52  53  54  55  56  59  60\n",
      "  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n",
      "  79  80  81  82  83  84  85  86  87  89  92  93  94  95  96  97  98  99\n",
      " 100 101 102 103 104 105 106 108 109 110 111 112 113 114 115 116 117 118\n",
      " 119 120 121 122 123 125 126 127 128 130 131 132 133 134 135 136 137 138\n",
      " 139 141 142 143 145 146 147 148 149]\n",
      "Test Index:  [  1  21  37  41  48  57  58  88  90  91 107 124 129 140 144] \n",
      "\n",
      "Train Index:  [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  15  16  17  18\n",
      "  19  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37\n",
      "  38  39  40  41  42  43  44  45  46  47  48  49  50  51  53  54  55  56\n",
      "  57  58  59  60  61  62  63  64  65  66  67  68  69  70  72  73  75  76\n",
      "  77  78  79  80  81  82  83  84  85  86  88  89  90  91  93  94  95  96\n",
      "  97  98 100 101 104 105 107 108 109 110 111 112 113 114 115 117 118 119\n",
      " 120 122 123 124 125 126 127 128 129 131 132 133 134 135 136 137 138 139\n",
      " 140 141 142 143 144 145 146 147 148]\n",
      "Test Index:  [ 14  20  52  71  74  87  92  99 102 103 106 116 121 130 149] \n",
      "\n",
      "accuracy of each fold - [1.0, 1.0, 1.0, 1.0, 1.0, 0.8666666666666667, 0.9333333333333333, 1.0, 1.0, 0.9333333333333333]\n",
      "Avg accuracy : 0.9733333333333334\n"
     ]
    }
   ],
   "source": [
    "k = 10\n",
    "acc_score = []\n",
    "cv = KFold(n_splits=k, random_state=42, shuffle=True)\n",
    "for train_index , test_index in cv.split(X):\n",
    "  print(\"Train Index: \", train_index)\n",
    "  print(\"Test Index: \", test_index, \"\\n\")\n",
    "  X_train , X_test = X.iloc[train_index,:],X.iloc[test_index,:]\n",
    "  y_train , y_test = y[train_index] , y[test_index]\n",
    "\n",
    "  model.fit(X_train,y_train)\n",
    "  pred_values = model.predict(X_test)\n",
    "     \n",
    "  acc = accuracy_score(pred_values , y_test)\n",
    "  acc_score.append(acc)\n",
    "     \n",
    "avg_acc_score = sum(acc_score)/k\n",
    " \n",
    "print('accuracy of each fold - {}'.format(acc_score))\n",
    "print('Avg accuracy : {}'.format(avg_acc_score))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
