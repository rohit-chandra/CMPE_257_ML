{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92ee29ce",
   "metadata": {},
   "source": [
    "\n",
    "# Name: Rohit Chandra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad36ef3",
   "metadata": {},
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a626bc1e",
   "metadata": {},
   "source": [
    "## 1 Explain what is Regularization? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4857a7c1",
   "metadata": {},
   "source": [
    "ðŸ‘‰ One of the major aspects of training your machine learning model is avoiding **overfitting.** The model will have a low accuracy if it is overfitting. This happens because your **model is trying too hard to capture the noise in your training dataset.** By noise we mean the data points that donâ€™t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.\n",
    "\n",
    "\n",
    "ðŸ‘‰ Overfitting is a phenomenon that occurs when a **Machine Learning model is constraint to training set and not able to perform well on unseen data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13fd161",
   "metadata": {},
   "source": [
    "![](images/overtfitting.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf84dbe2",
   "metadata": {},
   "source": [
    "**Regularization:**\n",
    "\n",
    "ðŸ‘‰ This is a form of regression, that constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique **discourages learning a more complex or flexible model, so as to avoid the risk of overfitting.**\n",
    "\n",
    "***(OR)***\n",
    "\n",
    "ðŸ‘‰ **Regularization** is a technique used to reduce the errors by fitting the function appropriately on the given training set and avoid overfitting. \n",
    "\n",
    "ðŸ‘‰ The commonly used regularization techniques are : \n",
    "\n",
    "+ **LASSO Regression (L1 regularization)**\n",
    "\n",
    "\n",
    "+ **Ridge regression (L2 regularization)**\n",
    "\n",
    "ðŸ‘‰ ***Note:***\n",
    "\n",
    "+ The full form of LASSO is **Least Absolute Shrinkage and Selection Operator regression**\n",
    "\n",
    "\n",
    "+ One of the ways of avoiding overfitting is using **cross validation**, that helps in estimating the error over test set, and in deciding what parameters work best for your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84adceb",
   "metadata": {},
   "source": [
    "## 2 Explain how regularization is performed in linear regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cfdbd9",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Regularization works by **adding a penalty or complexity term or shrinkage term with Residual Sum of Squares (RSS) to the complex model.**\n",
    "\n",
    "ðŸ‘‰ **Letâ€™s consider the Simple linear regression equation:**\n",
    "\n",
    "Here **Y represents the dependent feature or response which is the learned relation**. Then,\n",
    "\n",
    "Y is approximated to **Î²0 + Î²1X1 + Î²2X2 + â€¦+ Î²pXp**\n",
    "\n",
    "Here, **X1, X2, â€¦Xp** are the independent features or predictors for Y, and\n",
    "\n",
    "**Î²0, Î²1,â€¦..Î²n** represents the coefficients estimates for different variables or predictors(X), which describes the weights or magnitude attached to the features, respectively.\n",
    "\n",
    "ðŸ‘‰ In simple linear regression, our **optimization function or loss function is known as the residual sum of squares (RSS).**\n",
    "\n",
    "We choose those set of coefficients, such that the following loss function is minimized:\n",
    "\n",
    "\n",
    "ðŸ‘‰ **Below is th Cost Function For Simple Linear Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed3dfef0",
   "metadata": {},
   "source": [
    "![](images/cost_function_Linear_regression.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9adf7ce",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Now, this will **adjust the coefficient estimates based on the training data.** If there is **noise present in the training data, then the estimated coefficients wonâ€™t generalize well and are not able to predict the future data.**\n",
    "\n",
    "ðŸ‘‰ This is where **regularization comes into the picture, which shrinks or regularizes these learned estimates towards zero, by adding a loss function with optimizing parameters to make a model that can predict the accurate value of Y.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4292d17e",
   "metadata": {},
   "source": [
    "## 3 Explain what is Ridge and Lasso regression? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d2be263",
   "metadata": {},
   "source": [
    "### Ridge regression:\n",
    "\n",
    "ðŸ‘‰ Ridge regression is one of the types of linear regression in which we introduce a small amount of bias, known as Ridge regression penalty so that we can get better long-term predictions.\n",
    "\n",
    "ðŸ‘‰ In Statistics, it is known as the L-2 norm.\n",
    "\n",
    "ðŸ‘‰ In this technique, the cost function is altered by adding the penalty term (shrinkage term), which multiplies the lambda with the squared weight of each individual feature. Therefore, the optimization function(cost function) becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16c767e4",
   "metadata": {},
   "source": [
    "![](images/ridge.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41db58fd",
   "metadata": {},
   "source": [
    "ðŸ‘‰ Here, **Î» is the tuning parameter that decides how much we want to penalize the flexibility of our model.** The increase in flexibility of a model is represented by increase in its coefficients, and if we want to minimize the above function, then these coefficients need to be small. This is how the Ridge regression technique prevents coefficients from rising too high. Also, notice that we shrink the estimated association of each variable with the response, except the intercept Î²0, This intercept is a measure of the mean value of the response when xi1 = xi2 = â€¦= xip = 0.\n",
    "\n",
    "ðŸ‘‰ When **Î» = 0, the penalty term has no eï¬€ect, and the estimates produced by ridge regression will be equal to least squares.** However, as **Î»â†’âˆž, the impact of the shrinkage penalty grows, and the ridge regression coeï¬ƒcient estimates will approach zero.** As can be seen, selecting a good value of Î» is critical. Cross validation comes in handy for this purpose. The coefficient estimates produced by this method are also known as the L2 norm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8195ef76",
   "metadata": {},
   "source": [
    "ðŸ‘‰ **Usage of Ridge Regression:**\n",
    "\n",
    "+ When we have the independent variables which are having high collinearity (problem of ) between them, at that time general linear or polynomial regression will fail so to solve such problems, Ridge regression can be used.\n",
    "\n",
    "\n",
    "+ If we have more parameters than the samples, then Ridge regression helps to solve the problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710cbf57",
   "metadata": {},
   "source": [
    "ðŸ‘‰ **Limitation of Ridge Regression:**\n",
    "\n",
    "+ **Not helps in Feature Selection:** It decreases the complexity of a model but does not reduce the number of independent variables since it never leads to a coefficient being zero rather only minimizes it. Hence, this technique is not good for feature selection.\n",
    "\n",
    "\n",
    "+ **Model Interpretability:** Its disadvantage is model interpretability since it will shrink the coefficients for least important predictors, very close to zero but it will never make them exactly zero. In other words, the final model will include all the independent variables, also known as predictors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b92716",
   "metadata": {},
   "source": [
    "### Lasso Regression:\n",
    "\n",
    "\n",
    "ðŸ‘‰ Lasso regression is another variant of the regularization technique used to reduce the complexity of the model. It stands for **Least Absolute and Selection Operator.**\n",
    "\n",
    "ðŸ‘‰ It is similar to the Ridge Regression except that the **penalty term includes the absolute weights instead of a square of weights.** Therefore, the optimization function becomes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def597ab",
   "metadata": {},
   "source": [
    "![](images/lasso.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839fe91d",
   "metadata": {},
   "source": [
    "ðŸ‘‰ In statistics, it is known as the **L-1 norm.**\n",
    "\n",
    "ðŸ‘‰ In this technique, the **L1 penalty has the eï¬€ect of forcing some of the coeï¬ƒcient estimates to be exactly equal to zero which means there is a complete removal of some of the features for model evaluation when the tuning parameter Î» is suï¬ƒciently large.** Therefore, the lasso method also performs Feature selection and is said to yield sparse models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e81f5e20",
   "metadata": {},
   "source": [
    "ðŸ‘‰ **Limitation of Lasso Regression:**\n",
    "\n",
    "+ Problems with some types of Dataset: If the number of predictors is greater than the number of data points, Lasso will pick at most n predictors as non-zero, even if all predictors are relevant.\n",
    "\n",
    "\n",
    "+ Multicollinearity Problem: If there are two or more highly collinear variables then LASSO regression selects one of them randomly which is not good for the interpretation of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93927d2c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-24T03:34:10.630650Z",
     "start_time": "2022-02-24T03:34:10.615687Z"
    }
   },
   "source": [
    "**Key Differences between Ridge and Lasso Regression:**\n",
    "\n",
    "ðŸ‘‰ Ridge regression helps us to reduce only the overfitting in the model while keeping all the features present in the model. It reduces the complexity of the model by shrinking the coefficients whereas Lasso regression helps in reducing the problem of overfitting in the model as well as automatic feature selection.\n",
    "\n",
    "ðŸ‘‰ Lasso Regression tends to make coefficients to absolute zero whereas Ridge regression never sets the value of coefficient to absolute zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcc0b28",
   "metadata": {},
   "source": [
    "## 4 Perform Ridge and Lasso regression continuing the task of the previous homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "44ddc920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:15:58.174388Z",
     "start_time": "2022-02-26T23:15:58.164452Z"
    }
   },
   "outputs": [],
   "source": [
    "#import all the libraries\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3e43462f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:06:06.028653Z",
     "start_time": "2022-02-26T23:06:05.863238Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\IDEs\\Anaconda\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "boston_dataset = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cd43bf98",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:06:06.407808Z",
     "start_time": "2022-02-26T23:06:06.281965Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#save in dataframe\n",
    "boston = pd.DataFrame(boston_dataset.data, columns=boston_dataset.feature_names)\n",
    "boston.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "95b9aaaa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:06:06.803127Z",
     "start_time": "2022-02-26T23:06:06.790000Z"
    }
   },
   "outputs": [],
   "source": [
    "#add the target varaible to the datatframe\n",
    "boston['MEDV'] = boston_dataset.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "fed649af",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:06:07.253579Z",
     "start_time": "2022-02-26T23:06:07.135174Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the indpendent and dependent variables\n",
    "X = boston.iloc[:, boston.columns != 'MEDV']  #selecting all columns except \"MEDV\"\n",
    "y = boston.iloc[:, -1] #selecting target(MEDV in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "628101ac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:06:07.546943Z",
     "start_time": "2022-02-26T23:06:07.486293Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train1 is:  (379, 13)\n",
      "shape of X_test1 is:  (127, 13)\n",
      "shape of y_train1 is:  (379,)\n",
      "shape of y_test1 is:  (127,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test for model 1 and reseting the index to avoid jumbled index\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X, y, test_size = 0.25, random_state = 100)\n",
    "\n",
    "X_train1 = X_train1.reset_index(drop = True)\n",
    "X_test1 = X_test1.reset_index(drop = True)\n",
    "y_train1 = y_train1.reset_index(drop = True)\n",
    "y_test1 = y_test1.reset_index(drop = True)\n",
    "\n",
    "print(\"shape of X_train1 is: \", X_train1.shape)\n",
    "print(\"shape of X_test1 is: \", X_test1.shape)\n",
    "print(\"shape of y_train1 is: \", y_train1.shape)\n",
    "print(\"shape of y_test1 is: \", y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c9c64a72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:06:08.071405Z",
     "start_time": "2022-02-26T23:06:07.993147Z"
    }
   },
   "outputs": [],
   "source": [
    "#we can either use Standardization or Normalization here. Let's choose normalization\n",
    "\n",
    "# min max scaling the variables\n",
    "\n",
    "scaler =  MinMaxScaler()\n",
    "scaler.fit(X_train1)\n",
    "X_train_scaled1 = scaler.transform(X_train1)\n",
    "X_test_scaled1 = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "333378ff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:06:15.692791Z",
     "start_time": "2022-02-26T23:06:15.489976Z"
    }
   },
   "outputs": [],
   "source": [
    "# training linear regression model on the training set\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "lasso_regressor = Lasso(alpha = 0.1)\n",
    "\n",
    "#train 1st model\n",
    "lasso_regressor.fit(X_train_scaled1,y_train1)\n",
    "\n",
    "\n",
    "# making predictions for the training set 1\n",
    "y_train_pred1 = lasso_regressor.predict(X_train_scaled1)\n",
    "\n",
    "# making predictions for the testing set\n",
    "#dataset 1\n",
    "y_test_pred1 = lasso_regressor.predict(X_test_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6ec2063f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:07.762339Z",
     "start_time": "2022-02-26T23:07:07.746355Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score_Lasso for train = 0.6944635338817471\n",
      "R2_score_Lasso for test = 0.6657090543720645\n"
     ]
    }
   ],
   "source": [
    "print(\"R2_score_Lasso for train =\", r2_score(y_train1, y_train_pred1))\n",
    "print(\"R2_score_Lasso for test =\", r2_score(y_test1, y_test_pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ab35e3e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:09.473995Z",
     "start_time": "2022-02-26T23:07:08.942805Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_regressor = Ridge(alpha = 0.1)\n",
    "\n",
    "#train 1st model\n",
    "ridge_regressor.fit(X_train_scaled1,y_train1)\n",
    "\n",
    "y_pred = ridge_regressor.predict(X_test_scaled1)\n",
    "\n",
    "\n",
    "# making predictions for the training set 1\n",
    "y_train_pred1 = ridge_regressor.predict(X_train_scaled1)\n",
    "\n",
    "# making predictions for the testing set\n",
    "#dataset 1\n",
    "y_test_pred1 = ridge_regressor.predict(X_test_scaled1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "5d2f90a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:10.056433Z",
     "start_time": "2022-02-26T23:07:10.038449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score_Ridge for train = 0.7421080815376433\n",
      "R2_score_Ridge for test= 0.7233326093985133\n"
     ]
    }
   ],
   "source": [
    "print(\"R2_score_Ridge for train =\", r2_score(y_train1, y_train_pred1))\n",
    "print(\"R2_score_Ridge for test=\", r2_score(y_test1, y_test_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545b97f",
   "metadata": {},
   "source": [
    "## 5 Perform Ridge and Lasso regression on HCC.csv dataset after performing necessary pre-processing steps as mentioned in the previous homework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9688d57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:14.616784Z",
     "start_time": "2022-02-26T23:07:14.544913Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (window._pyforest_update_imports_cell) { window._pyforest_update_imports_cell('import pandas as pd'); }\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hcc_df = pd.read_csv('D:/Masters/SJSU/Academics/sem_2/CMPE_257_ML/Assignments/HW3/data/HCC.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "44ce3a2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:15.309229Z",
     "start_time": "2022-02-26T23:07:15.264953Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>1.Gen</th>\n",
       "      <th>2.Sym</th>\n",
       "      <th>3.Alc</th>\n",
       "      <th>4.HepB</th>\n",
       "      <th>6.HepB</th>\n",
       "      <th>7.HepC</th>\n",
       "      <th>8.Cir</th>\n",
       "      <th>11.Dia</th>\n",
       "      <th>12.Obe</th>\n",
       "      <th>...</th>\n",
       "      <th>37.Bil</th>\n",
       "      <th>38.Ala</th>\n",
       "      <th>39.Aspa</th>\n",
       "      <th>40.Gam</th>\n",
       "      <th>41.Alk</th>\n",
       "      <th>42.Prot</th>\n",
       "      <th>43.Crea</th>\n",
       "      <th>44.NNod</th>\n",
       "      <th>45.dnod</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>41</td>\n",
       "      <td>183.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>68</td>\n",
       "      <td>202.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.10</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>64</td>\n",
       "      <td>94.0</td>\n",
       "      <td>174.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1.11</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.7</td>\n",
       "      <td>147.0</td>\n",
       "      <td>306</td>\n",
       "      <td>173.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>91.0</td>\n",
       "      <td>122</td>\n",
       "      <td>242.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  1.Gen  2.Sym  3.Alc  4.HepB  6.HepB  7.HepC  8.Cir  11.Dia  \\\n",
       "0           0      1    0.0      1     0.0     0.0     0.0      1     1.0   \n",
       "1           2      1    0.0      1     1.0     1.0     0.0      1     0.0   \n",
       "2           3      1    1.0      1     0.0     0.0     0.0      1     1.0   \n",
       "3           4      1    1.0      1     1.0     1.0     0.0      1     0.0   \n",
       "4           5      1    0.0      1     0.0     0.0     0.0      1     0.0   \n",
       "\n",
       "   12.Obe  ...  37.Bil  38.Ala  39.Aspa  40.Gam  41.Alk  42.Prot  43.Crea  \\\n",
       "0     0.0  ...     2.1    34.0       41   183.0   150.0      7.1     0.70   \n",
       "1     0.0  ...     0.4    58.0       68   202.0   109.0      7.0     2.10   \n",
       "2     0.0  ...     0.4    16.0       64    94.0   174.0      8.1     1.11   \n",
       "3     0.0  ...     0.7   147.0      306   173.0   109.0      6.9     1.80   \n",
       "4     1.0  ...     3.5    91.0      122   242.0   396.0      5.6     0.90   \n",
       "\n",
       "   44.NNod  45.dnod  Class  \n",
       "0      1.0      3.5      1  \n",
       "1      5.0     13.0      1  \n",
       "2      2.0     15.7      0  \n",
       "3      1.0      9.0      1  \n",
       "4      1.0     10.0      0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hcc_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "45106756",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:15.748023Z",
     "start_time": "2022-02-26T23:07:15.736057Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156, 41)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hcc_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44a8ca66",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:16.446990Z",
     "start_time": "2022-02-26T23:07:16.227680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 156 entries, 0 to 155\n",
      "Data columns (total 41 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   Unnamed: 0     156 non-null    int64  \n",
      " 1   1.Gen          156 non-null    int64  \n",
      " 2   2.Sym          156 non-null    float64\n",
      " 3   3.Alc          156 non-null    int64  \n",
      " 4   4.HepB         156 non-null    float64\n",
      " 5   6.HepB         156 non-null    float64\n",
      " 6   7.HepC         156 non-null    float64\n",
      " 7   8.Cir          156 non-null    int64  \n",
      " 8   11.Dia         156 non-null    float64\n",
      " 9   12.Obe         156 non-null    float64\n",
      " 10  13.Hem         156 non-null    float64\n",
      " 11  14.Art         156 non-null    float64\n",
      " 12  15.CRen        156 non-null    float64\n",
      " 13  16.HIV         156 non-null    float64\n",
      " 14  17.Non         156 non-null    float64\n",
      " 15  19.Spl         156 non-null    float64\n",
      " 16  20.PHyp        156 non-null    float64\n",
      " 17  21.Thr         156 non-null    float64\n",
      " 18  22.LMet        156 non-null    float64\n",
      " 19  23.Rad         156 non-null    float64\n",
      " 20  24.Agedia      156 non-null    int64  \n",
      " 21  27.Sta         156 non-null    int64  \n",
      " 22  28.Encdeg      156 non-null    float64\n",
      " 23  29.Ascdeg      156 non-null    float64\n",
      " 24   30.IntNorRat  156 non-null    float64\n",
      " 25   31.Alp        156 non-null    float64\n",
      " 26   32.Hae        156 non-null    float64\n",
      " 27   33.MCorVol    156 non-null    float64\n",
      " 28   34.Leu        156 non-null    float64\n",
      " 29  35.Plat        156 non-null    float64\n",
      " 30  36.Alb         156 non-null    float64\n",
      " 31  37.Bil         156 non-null    float64\n",
      " 32  38.Ala         156 non-null    float64\n",
      " 33  39.Aspa        156 non-null    int64  \n",
      " 34  40.Gam         156 non-null    float64\n",
      " 35  41.Alk         156 non-null    float64\n",
      " 36  42.Prot        156 non-null    float64\n",
      " 37  43.Crea        156 non-null    float64\n",
      " 38  44.NNod        156 non-null    float64\n",
      " 39  45.dnod        156 non-null    float64\n",
      " 40  Class          156 non-null    int64  \n",
      "dtypes: float64(33), int64(8)\n",
      "memory usage: 50.1 KB\n"
     ]
    }
   ],
   "source": [
    "Hcc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "132ee3c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:16.698255Z",
     "start_time": "2022-02-26T23:07:16.677979Z"
    }
   },
   "outputs": [],
   "source": [
    "# Selecting the indpendent and dependent variables\n",
    "X_hcc = Hcc_df.iloc[:, Hcc_df.columns != 'Class']  #selecting all columns except \"MEDV\"\n",
    "y_hcc = Hcc_df.iloc[:, -1] #selecting target(MEDV in this case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "00dc40f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:17.177835Z",
     "start_time": "2022-02-26T23:07:17.164062Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of X_train1 is:  (117, 40)\n",
      "shape of X_test1 is:  (39, 40)\n",
      "shape of y_train1 is:  (117,)\n",
      "shape of y_test1 is:  (39,)\n"
     ]
    }
   ],
   "source": [
    "# Splitting into train and test for model 1 and reseting the index to avoid jumbled index\n",
    "\n",
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X_hcc, y_hcc, test_size = 0.25, random_state = 100)\n",
    "\n",
    "X_train1 = X_train1.reset_index(drop = True)\n",
    "X_test1 = X_test1.reset_index(drop = True)\n",
    "y_train1 = y_train1.reset_index(drop = True)\n",
    "y_test1 = y_test1.reset_index(drop = True)\n",
    "\n",
    "print(\"shape of X_train1 is: \", X_train1.shape)\n",
    "print(\"shape of X_test1 is: \", X_test1.shape)\n",
    "print(\"shape of y_train1 is: \", y_train1.shape)\n",
    "print(\"shape of y_test1 is: \", y_test1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "8e6f7452",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:17.726790Z",
     "start_time": "2022-02-26T23:07:17.713357Z"
    }
   },
   "outputs": [],
   "source": [
    "#1st model\n",
    "scaler =  MinMaxScaler()\n",
    "scaler.fit(X_train1)\n",
    "X_train_scaled1 = scaler.transform(X_train1)\n",
    "X_test_scaled1 = scaler.transform(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a188933c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:19.259990Z",
     "start_time": "2022-02-26T23:07:19.251024Z"
    }
   },
   "outputs": [],
   "source": [
    "# training linear regression model on the training set\n",
    "\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "lasso_regressor = Lasso(alpha = 0.1)\n",
    "\n",
    "#train 1st model\n",
    "lasso_regressor.fit(X_train_scaled1,y_train1)\n",
    "\n",
    "\n",
    "# making predictions for the training set 1\n",
    "y_train_pred1 = lasso_regressor.predict(X_train_scaled1)\n",
    "\n",
    "# making predictions for the testing set\n",
    "#dataset 1\n",
    "y_test_pred1 = lasso_regressor.predict(X_test_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "72d22516",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:07:22.091893Z",
     "start_time": "2022-02-26T23:07:22.076933Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score_Lasso for train = 0.0\n",
      "R2_score_Lasso for test = -0.0028571428571422253\n"
     ]
    }
   ],
   "source": [
    "print(\"R2_score_Lasso for train =\", r2_score(y_train1, y_train_pred1))\n",
    "print(\"R2_score_Lasso for test =\", r2_score(y_test1, y_test_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69f9a31",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "+  The lasso regressor model is performing worse(on the test data when comapred to train data) than the average fit line hence the R2 score is negative because the predictor is a categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "8360f086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:08:18.032223Z",
     "start_time": "2022-02-26T23:08:18.008249Z"
    }
   },
   "outputs": [],
   "source": [
    "ridge_regressor = Ridge(alpha = 0.1)\n",
    "\n",
    "#train 1st model\n",
    "ridge_regressor.fit(X_train_scaled1,y_train1)\n",
    "\n",
    "y_pred = ridge_regressor.predict(X_test_scaled1)\n",
    "\n",
    "\n",
    "# making predictions for the training set 1\n",
    "y_train_pred1 = ridge_regressor.predict(X_train_scaled1)\n",
    "\n",
    "# making predictions for the testing set\n",
    "#dataset 1\n",
    "y_test_pred1 = ridge_regressor.predict(X_test_scaled1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "de104981",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-26T23:08:18.573475Z",
     "start_time": "2022-02-26T23:08:18.545789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_score_Lasso for train = 0.5551765520335733\n",
      "R2_score_Lasso for test = -0.1486760724824705\n"
     ]
    }
   ],
   "source": [
    "print(\"R2_score_Lasso for train =\", r2_score(y_train1, y_train_pred1))\n",
    "print(\"R2_score_Lasso for test =\", r2_score(y_test1, y_test_pred1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41952720",
   "metadata": {},
   "source": [
    "**Observation:**\n",
    "\n",
    "+  The Ridge regressor model is performing worse(on the test data when comapred to train data) than the average fit line hence the R2 score is negative because the predictor is a categorical data and we need to apply logistic regression model on this data to get better results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103248e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9021f049",
   "metadata": {},
   "source": [
    "Sources:\n",
    "\n",
    "+ https://towardsdatascience.com/regularization-in-machine-learning-76441ddcf99a\n",
    "\n",
    "\n",
    "+ https://www.analyticsvidhya.com/blog/2021/05/complete-guide-to-regularization-techniques-in-machine-learning/#:~:text=Regularization%20works%20by%20adding%20a,RSS)%20to%20the%20complex%20model.&text=%CE%B20%2C%20%CE%B21%2C%E2%80%A6..&text=In%20simple%20linear%20regression%2C%20our,sum%20of%20squares%20(RSS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8071d970",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
